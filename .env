# ===== VOSK MODEL CONFIGURATION =====
# Defines the path to the Vosk model and the URL to download it from.
# For better accuracy, consider using larger models for your language
VOSK_MODEL_PATH="models/vosk-model-en-in-0.5"
VOSK_MODEL_URL="https://alphacephei.com/vosk/models/vosk-model-en-in-0.5.zip"

# ===== ADVANCED SPEECH RECOGNITION SETTINGS =====

# RECOGNIZER_SAMPLE_RATE: The sample rate for the audio stream in Hz.
# Higher sample rates provide better quality but use more resources
# Standard options: 8000, 16000, 44100, 48000
RECOGNIZER_SAMPLE_RATE=16000

# NOISE_CALIBRATION_DURATION: Duration for initial ambient noise assessment
# Longer calibration provides better noise baseline but delays startup
NOISE_CALIBRATION_DURATION=3.0

# VAD_AGGRESSIVENESS: Voice Activity Detection sensitivity (0-3)
# 0: Least aggressive, good for quiet environments
# 1: Moderate, balanced for most environments
# 2: More aggressive, good for moderately noisy environments
# 3: Most aggressive, for very noisy environments (may clip speech)
VAD_AGGRESSIVENESS=2

# SILENCE_THRESHOLD: Duration of silence to consider a phrase complete (seconds)
# This is critical for natural conversation flow
# Lower values (1.0-1.5): More responsive but may cut off mid-sentence
# Higher values (2.5-4.0): Better for natural pauses and thinking time
SILENCE_THRESHOLD=2.8

# PHRASE_TIMEOUT: Maximum duration for a single phrase (seconds)
# Prevents the recognizer from listening indefinitely
# Should be longer than typical sentence duration
PHRASE_TIMEOUT=20.0

# ===== ADVANCED AUDIO PROCESSING =====

# AUDIO_CHUNK_SIZE: Size of audio chunks for processing
# Smaller chunks = lower latency, larger chunks = better accuracy
# Must be compatible with VAD frame requirements (160, 320, or 480 samples for 16kHz)
AUDIO_CHUNK_SIZE=480

# ENERGY_THRESHOLD: Minimum audio energy to consider as potential speech
# Higher values filter out more background noise but may miss quiet speech
# Range: 50-4000, typical: 300-1500
ENERGY_THRESHOLD=800

# DYNAMIC_ENERGY_THRESHOLD: Enable automatic energy threshold adjustment
# Adapts to changing noise conditions over time
DYNAMIC_ENERGY_THRESHOLD=true

# DYNAMIC_ENERGY_ADJUSTMENT_DAMPING: How quickly to adapt energy threshold (0.0-1.0)
# Lower values adapt faster, higher values are more stable
DYNAMIC_ENERGY_ADJUSTMENT_DAMPING=0.15

# DYNAMIC_ENERGY_RATIO: Ratio above ambient energy to trigger speech detection
# Higher values are more conservative, lower values are more sensitive
DYNAMIC_ENERGY_RATIO=1.5

# ===== SPEECH ENDPOINTING =====

# MIN_SPEECH_DURATION: Minimum duration of speech to process (seconds)
# Filters out very short sounds that are unlikely to be meaningful speech
MIN_SPEECH_DURATION=0.3

# MAX_SILENCE_IN_SPEECH: Maximum allowed silence within a speech segment (seconds)
# Allows for natural pauses within sentences without splitting them
MAX_SILENCE_IN_SPEECH=0.8

# SPEECH_PADDING: Audio padding before/after detected speech (seconds)
# Ensures we don't cut off the beginning or end of words
SPEECH_PADDING_BEFORE=0.2
SPEECH_PADDING_AFTER=0.2

# ===== RECOGNITION CONFIDENCE =====

# MIN_CONFIDENCE_THRESHOLD: Minimum confidence score to accept a result (0.0-1.0)
# Higher values filter out uncertain results but may miss valid speech
MIN_CONFIDENCE_THRESHOLD=0.3

# ENABLE_CONFIDENCE_FILTERING: Whether to use confidence-based filtering
ENABLE_CONFIDENCE_FILTERING=true

# ===== TEXT POST-PROCESSING =====

# ENABLE_GRAMMAR_CORRECTION: Enable automatic grammar correction
ENABLE_GRAMMAR_CORRECTION=true

# ENABLE_SPELL_CHECK: Enable spell checking and correction
ENABLE_SPELL_CHECK=true

# ENABLE_CUSTOM_VOCABULARY: Use custom vocabulary for better recognition
ENABLE_CUSTOM_VOCABULARY=true

# CUSTOM_VOCABULARY_PATH: Path to custom vocabulary file
CUSTOM_VOCABULARY_PATH="config/custom_vocabulary.json"

# ENABLE_PROFANITY_FILTER: Filter out profanity from results
ENABLE_PROFANITY_FILTER=false

# TEXT_NORMALIZATION: Enable text normalization (numbers, dates, etc.)
ENABLE_TEXT_NORMALIZATION=true

# ===== LOGGING AND OUTPUT =====

# LOG_LEVEL: Logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ENABLE_DETAILED_LOGGING: Log detailed recognition statistics
ENABLE_DETAILED_LOGGING=true

# LOG_AUDIO_STATS: Log audio level and quality statistics
LOG_AUDIO_STATS=true

# ENABLE_TIMESTAMPS: Include timestamps in transcription output
ENABLE_TIMESTAMPS=true

# TIMESTAMP_FORMAT: Format for timestamps
TIMESTAMP_FORMAT=%Y-%m-%d %H:%M:%S

# ===== PERFORMANCE OPTIMIZATION =====

# ENABLE_MULTIPROCESSING: Use multiple processes for better performance
ENABLE_MULTIPROCESSING=false

# NUM_WORKER_THREADS: Number of worker threads for processing
NUM_WORKER_THREADS=2

# BUFFER_SIZE: Size of audio buffer (number of chunks)
# Larger buffers handle temporary processing delays better
AUDIO_BUFFER_SIZE=50

# REALTIME_PROCESSING: Prioritize real-time processing over accuracy
REALTIME_PROCESSING=true

# ===== ADVANCED FEATURES =====

# ENABLE_SPEAKER_ADAPTATION: Adapt to specific speaker characteristics over time
ENABLE_SPEAKER_ADAPTATION=false

# ENABLE_NOISE_SUPPRESSION: Additional noise suppression beyond VAD
ENABLE_NOISE_SUPPRESSION=true

# NOISE_SUPPRESSION_LEVEL: Noise suppression strength (0.0-1.0)
NOISE_SUPPRESSION_LEVEL=0.3

# ENABLE_ECHO_CANCELLATION: Cancel audio feedback/echo
ENABLE_ECHO_CANCELLATION=true

# ===== FALLBACK AND ERROR HANDLING =====

# MAX_RETRIES: Maximum number of retries for failed operations
MAX_RETRIES=3

# RETRY_DELAY: Delay between retries (seconds)
RETRY_DELAY=1.0

# FALLBACK_TO_PARTIAL: Use partial results if final recognition fails
FALLBACK_TO_PARTIAL=true

# ENABLE_RECOVERY_MODE: Attempt to recover from audio stream errors
ENABLE_RECOVERY_MODE=true

# ===== CUSTOM VOCABULARY SETTINGS =====

# These names will be recognized with high priority
PRIORITY_NAMES=Quip,Oracle,Byte,Mika,Kira

# Custom technical terms and domain-specific vocabulary
TECHNICAL_TERMS=API,database,server,client,frontend,backend,microservices

# Common abbreviations and acronyms
ABBREVIATIONS=AI,ML,NLP,UI,UX,API,HTTP,JSON,XML,SQL